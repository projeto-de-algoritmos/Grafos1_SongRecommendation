{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_graph = {'Do I Wanna Know?': ['indie rock', 'indie', 'alternative'],\n",
    " 'indie rock': ['Do I Wanna Know?', 'Mr. Brightside', 'R U Mine?'],\n",
    " 'indie': ['Do I Wanna Know?',\n",
    "  'Mr. Brightside',\n",
    "  'R U Mine?',\n",
    "  'Pumped Up Kicks',\n",
    "  'The Less I Know the Better'],\n",
    " 'alternative': ['Do I Wanna Know?',\n",
    "  'Losing My Religion',\n",
    "  'Seven Nation Army',\n",
    "  'The Less I Know the Better'],\n",
    " 'Mr. Brightside': ['rock', 'indie', 'indie rock'],\n",
    " 'rock': ['Mr. Brightside',\n",
    "  'Losing My Religion',\n",
    "  'Seven Nation Army',\n",
    "  'Smells Like Teen Spirit'],\n",
    " 'R U Mine?': ['indie rock', 'indie', 'british'],\n",
    " 'british': ['R U Mine?'],\n",
    " 'Take on Me': ['80s', 'pop', 'new wave'],\n",
    " '80s': ['Take on Me'],\n",
    " 'pop': ['Take on Me', 'Sorry'],\n",
    " 'new wave': ['Take on Me'],\n",
    " 'Pumped Up Kicks': ['indie', 'indie pop', 'catchy'],\n",
    " 'indie pop': ['Pumped Up Kicks'],\n",
    " 'catchy': ['Pumped Up Kicks'],\n",
    " 'Losing My Religion': ['rock', '90s', 'alternative'],\n",
    " '90s': ['Losing My Religion','pop'],\n",
    " 'Seven Nation Army': ['rock', 'alternative rock', 'alternative'],\n",
    " 'alternative rock': ['Seven Nation Army'],\n",
    " 'Sorry': ['pop', 'justin bieber', 'dancehall'],\n",
    " 'justin bieber': ['Sorry'],\n",
    " 'dancehall': ['Sorry'],\n",
    " 'Smells Like Teen Spirit': ['Grunge', 'rock', 'Nirvana'],\n",
    " 'Grunge': ['Smells Like Teen Spirit'],\n",
    " 'Nirvana': ['Smells Like Teen Spirit'],\n",
    " 'The Less I Know the Better': ['indie', 'psychedelic', 'alternative'],\n",
    " 'psychedelic': ['The Less I Know the Better']}\n",
    "\n",
    "# _graph = nx.Graph()\n",
    "\n",
    "# _graph.add_nodes_from(list(songs_graph.keys()))\n",
    "\n",
    "# for node in list(songs_graph.keys()):\n",
    "#     for edge in songs_graph[node]:\n",
    "#         _graph.add_edge(node,edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diga uma música que você gostaUndisclosed desires\n"
     ]
    }
   ],
   "source": [
    "def lastfm_request(api_method,artist='',track=''):\n",
    "    \n",
    "    if api_method==0:\n",
    "        method = f\"track.gettoptags&artist={artist}&track={track}\"\n",
    "    else:\n",
    "        method = f\"track.search&track={track}&limit=1\"\n",
    "    \n",
    "    key =\"3dc1e72157f70010ef87db6b769fbfe7\"\n",
    "    API_URL = f'http://ws.audioscrobbler.com/2.0/?method={method}&api_key={key}&format=json'\n",
    "    return requests.request(method='get', url=API_URL).json()\n",
    "\n",
    "\n",
    "song_name = input(\"Diga uma música que você gosta\")\n",
    "result = lastfm_request(1,track=song_name)['results']['trackmatches']['track'][0]\n",
    "tags = lastfm_request(0,result['artist'],result['name'])['toptags']['tag'][:3]\n",
    "\n",
    "if result['name'] not in songs_graph:\n",
    "        songs_graph[result['name']] = []\n",
    "        for tag in tags:\n",
    "            songs_graph[result[\"name\"]].append(tag[\"name\"])\n",
    "            if tag[\"name\"] not in songs_graph:\n",
    "                songs_graph[tag[\"name\"]] = [result[\"name\"]]\n",
    "            else:\n",
    "                songs_graph[tag[\"name\"]].append(result[\"name\"])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'alternative', 'lenght': 2, 'number': 1}\n",
      "CPU times: user 18.5 ms, sys: 2.88 ms, total: 21.4 ms\n",
      "Wall time: 18.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def dfs_caminhos(grafo, inicio, fim):\n",
    "    pilha = [(inicio, [inicio])]\n",
    "    depth = 0\n",
    "    while pilha:\n",
    "        vertice, caminho = pilha.pop()\n",
    "        for proximo in set(grafo[vertice]) - set(caminho):\n",
    "            if proximo == fim:\n",
    "                yield caminho + [proximo]\n",
    "            else:\n",
    "                pilha.append((proximo, caminho + [proximo]))\n",
    "\n",
    "all_paths2 = []\n",
    "best_match = {\n",
    "    'name': '',\n",
    "    'lenght': 0,\n",
    "    'number': 0\n",
    "}\n",
    "for node in songs_graph:\n",
    "    answers = [len(x) for x in list(dfs_caminhos(songs_graph, node, result['name']))]\n",
    "#     lol = str(answers.count(min(answers)))+' '+str(min(answers)) if answers  else 'None'\n",
    "#     lel = f'{} {}' if answers else 'None'\n",
    "    if answers:\n",
    "        num_paths = answers.count(min(answers))\n",
    "        path_lenght = min(answers)\n",
    "        if path_lenght < best_match['lenght'] or best_match['lenght']==0 or (path_lenght ==best_match['lenght'] and num_paths >  best_match['number']) :\n",
    "            best_match['name'], best_match['lenght'], best_match['number'] = node, path_lenght, num_paths\n",
    "    \n",
    "#     all_paths2.append(f'{node}: {lel}')\n",
    "#     print(node + \": \"+str(lol))\n",
    "print(best_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 ms, sys: 0 ns, total: 1.01 ms\n",
      "Wall time: 1.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'alternative', 'lenght': 2, 'number': 1}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def _build_paths_from_predecessors(sources, target, pred):\n",
    "\n",
    "    if target not in pred or {target}==sources:\n",
    "        return None\n",
    "\n",
    "    seen = {target}\n",
    "    stack = [[target, 0]]\n",
    "    top = 0\n",
    "    while top >= 0:\n",
    "        node, i = stack[top]\n",
    "        if node in sources:\n",
    "            yield [p for p, n in reversed(stack[: top + 1])]\n",
    "        if len(pred[node]) > i:\n",
    "            stack[top][1] = i + 1\n",
    "            next = pred[node][i]\n",
    "            if next in seen:\n",
    "                continue\n",
    "            else:\n",
    "                seen.add(next)\n",
    "            top += 1\n",
    "            if top == len(stack):\n",
    "                stack.append([next, 0])\n",
    "            else:\n",
    "                stack[top][:] = [next, 0]\n",
    "        else:\n",
    "            seen.discard(node)\n",
    "            top -= 1\n",
    "\n",
    "def predecessor(G, source):\n",
    "\n",
    "    if source not in G:\n",
    "        raise nx.NodeNotFound(f\"Source {source} not in G\")\n",
    "\n",
    "    level = 0  # the current level\n",
    "    nextlevel = [source]  # list of nodes to check at next level\n",
    "    seen = {source: level}  # level (number of hops) when seen in BFS\n",
    "    pred = {source: []}  # predecessor dictionary\n",
    "    while nextlevel:\n",
    "        level = level + 1\n",
    "        thislevel = nextlevel\n",
    "        nextlevel = []\n",
    "        for v in thislevel:\n",
    "            for w in G[v]:\n",
    "                if w not in seen:\n",
    "                    pred[w] = [v]\n",
    "                    seen[w] = level\n",
    "                    nextlevel.append(w)\n",
    "                elif seen[w] == level:  \n",
    "                    pred[w].append(v)  \n",
    "\n",
    "    return pred\n",
    "\n",
    "# all_paths = []\n",
    "best_match = {\n",
    "    'name': '',\n",
    "    'lenght': 0,\n",
    "    'number': 0\n",
    "}\n",
    "for node in songs_graph:\n",
    "    parentage = predecessor(songs_graph, node)\n",
    "    paths = list(_build_paths_from_predecessors({node}, result['name'], parentage))\n",
    "    if paths != []:\n",
    "        num_paths = len(paths)\n",
    "        path_lenght = len(paths[0])\n",
    "        if path_lenght < best_match['lenght'] or best_match['lenght']==0 or (path_lenght ==best_match['lenght'] and num_paths >  best_match['number']) :\n",
    "            best_match['name'], best_match['lenght'], best_match['number'] = node, path_lenght, num_paths\n",
    "    \n",
    "best_match       \n",
    "    \n",
    "    \n",
    "#     if paths == []:\n",
    "#         all_paths.append(f'{node}: None')\n",
    "#     else:\n",
    "#         num = len(paths[0])\n",
    "#         all_paths.append(f'{node}: {len(paths)} {num} ')\n",
    "\n",
    "# print(all_paths)\n",
    "    \n",
    "# parentage = predecessor(songs_graph, 'Take on Me')\n",
    "# list(_build_paths_from_predecessors({'Take on Me'}, 'Undisclosed Desires', parentage))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
